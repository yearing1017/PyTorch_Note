# PyTorch_Note
â°PyTorchå­¦ä¹ ç¬”è®°
## ğŸ’¡ 1. Pytorch_tutorial
- [Pytorch_60min.md](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_60min.md)ï¼šå®˜æ–¹60åˆ†é’Ÿå…¥é—¨Pytorch
- [Pytorch_Basic.py](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_Basic.py)ï¼šè‡ªåŠ¨æ±‚å¯¼ã€æ•°æ®é›†çš„ä½¿ç”¨ã€æ¨¡å‹ä¿å­˜åŠè½½å…¥
- [Pytorch_linearRegression.py](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_linearRegression.py)ï¼šçº¿æ€§å›å½’ä¾‹å­å®ç°å®Œæ•´è®­ç»ƒ
- [Pytorch_logisticRegression.py](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_logisticRegression.py)ï¼šMINIST+é€»è¾‘å›å½’å®ç°è®­ç»ƒæµ‹è¯•
- [Pytorch_NNdemo.py](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_NNdemo.py)ï¼šMINIST+ç®€æ˜“ç¥ç»ç½‘ç»œå®ç°è®­ç»ƒæµ‹è¯•
- [Pytorch_CNN](https://github.com/yearing1017/PyTorch_Note/blob/master/Pytorch_CNN.py)ï¼šMINST+å·ç§¯ç¥ç»ç½‘ç»œè®­ç»ƒæµ‹è¯•
- [pytorch_cuda.ipynb](https://github.com/yearing1017/PyTorch_Note/blob/master/pytorch_cuda.ipynb)ï¼špytorchæœ‰å…³cudaçš„åŸºæœ¬æ“ä½œä¸æ¦‚å¿µ
- [LeNet.ipynb](https://github.com/yearing1017/PyTorch_Note/blob/master/LeNet.ipynb)ï¼špytorchæ­å»ºLeNetç½‘ç»œ
- [ResNet.ipynb](https://github.com/yearing1017/PyTorch_Note/blob/master/ResNet.ipynb)ï¼špytorchæ­å»ºResNet

## ğŸ’¡ 2. Pytorch_å·²è§£å†³é—®é¢˜_1

- åœ¨è·‘unetçš„æ¨¡å‹æ—¶ï¼Œé‡åˆ°è¯¥é”™è¯¯:

`RuntimeError: Given groups=1, weight of size 64 3 3 3, expected input[4, 64, 158, 158] to have 3 channels, but got 64 channels instead`

- é—®é¢˜æ˜¯è¾“å…¥æœ¬æ¥è¯¥æ˜¯ 3 channelsï¼Œä½†å´æ˜¯64é€šé“ã€‚

- è§£å†³æ€è·¯ï¼šæ‰“å°äº†ä¸€ä¸‹è¾“å…¥çš„size:[4,3,160,160],æœ¬æ¥ä»¥ä¸ºæ²¡é”™è¯¯ï¼Œå°±ä¸€ç›´åœ¨æ‰¾ã€‚

- å®é™…é—®é¢˜ï¼šå› ä¸ºæˆ‘åœ¨ä»¥ä¸‹ä»£ç éƒ¨åˆ†æœ‰ä¸¤ä¸ªå·ç§¯æ“ä½œï¼Œæˆ‘çš„ç¬¬äºŒä¸ªå·ç§¯çš„è¾“å…¥åº”è¯¥æ˜¯ç¬¬ä¸€ä¸ªå·ç§¯çš„è¾“å‡ºï¼Œæˆ‘å´è®¾å®šäº†ä¸¤è€…ç›¸åŒã€‚å¦‚ä¸‹ï¼š
```python
class DoubleConv(nn.Module):
	def __init__(self, in_channels, out_channels):
		super.__init__()
		# æ„å»ºä¸€ä¸ªâ€œå®¹å™¨ç½‘ç»œâ€
		self.double_conv = nn.Sequential(
			nn.Conv2d(in_channels,out_channels,kernel_size=3),
			nn.BatchNorm2d(out_channels),
			nn.ReLU(inplace=True),
			nn.Conv2d(in_channels,out_channels,kernel_size=3),
			nn.BatchNorm2d(out_channels),
			nn.ReLU(inplace=True)
		)
	def forward(self,x):
		return self.double_conv(x)
```

- åœ¨ç¬¬25è¡Œçš„å·ç§¯ä¸­ï¼Œæˆ‘çš„in_channelså’Œç¬¬ä¸€ä¸ªå·ç§¯çš„ä¸€æ ·ï¼Œä½†å´åº”è¯¥æ˜¯ç¬¬ä¸€ä¸ªçš„è¾“å‡ºï¼Œæ‰€ä»¥æ”¹ä¸ºout_channels,å¦‚ä¸‹ï¼š
```python
class DoubleConv(nn.Module):
	def __init__(self, in_channels, out_channels):
		super.__init__()
		# æ„å»ºä¸€ä¸ªâ€œå®¹å™¨ç½‘ç»œâ€
		self.double_conv = nn.Sequential(
			nn.Conv2d(in_channels,out_channels,kernel_size=3),
			nn.BatchNorm2d(out_channels),
			nn.ReLU(inplace=True),
			nn.Conv2d(out_channels,out_channels,kernel_size=3),
			nn.BatchNorm2d(out_channels),
			nn.ReLU(inplace=True)
		)
	def forward(self,x):
		return self.double_conv(x)
```

## ğŸ’¡ 3. Pytorch_cv2_Tensorç›¸å…³

- ä¸€ä¸ªç°åº¦çš„å›¾ç‰‡ï¼Œåªæœ‰ä¸€ä¸ªé€šé“ï¼Œåªæ˜¯cv2è¯»å–imageï¼Œæ‰“å°shapeï¼Œä»…ä»…æ˜¾ç¤º[H, W]

- è‹¥ä½¿ç”¨äº†torchvision.ToTensor()æ–¹æ³•ï¼Œå†æ‰“å°shapeï¼Œä¼šæ‰“å°å‡º[C, H, W],ä¸”è¿›è¡Œäº†å½’ä¸€åŒ–ï¼Œå–å€¼èŒƒå›´ä¸º[0,1.0]çš„torch.FloatTensor
```python
import cv2
import torch
import torchvision.transforms

image_name = 'Dataset/2d_images/ID_0000_Z_0142.tif'
image = cv2.imread(image_name, 0)
print(image.shape) # (512,512)
image_tensor = torchvision.transforms.ToTensor()(image)
print(image_tensor.shape) # torch.Size([1, 512, 512])
```

- è¿˜æœ‰ä¸€ç§æš´åŠ›æ–¹æ³•å¾—åˆ°æƒ³è¦çš„shapeï¼Œå…ˆresizeï¼Œå†reshapeï¼Œæœ€åå†è½¬ä¸ºtensorï¼Œè¿™æœŸé—´æ²¡æœ‰è¿›è¡Œå½’ä¸€åŒ–
```python
import torch
import torchvision.transforms
import cv2

image_name = 'Dataset/2d_images/ID_0000_Z_0142.tif'
image = cv2.imread(image_name, 0)
print(image.shape)
image = cv2.resize(image, (160, 160))
image_new = image.reshape((1, 160, 160))
image_tensor = torch.FloatTensor(image_new)
print(image_new.shape)
print(image_tensor.shape)

# è¾“å‡ºï¼š
(512, 512)
(1, 160, 160)
torch.Size([1, 160, 160])
```
- `cv2.resize(img, (width, height))`å‚æ•°æ˜¯:å…ˆå®½åé«˜

- **class torchvision.transforms.ToTensor**:
  - æŠŠä¸€ä¸ªå–å€¼èŒƒå›´æ˜¯`[0,255]`çš„`PIL.Image`æˆ–è€…`shape`ä¸º`(H,W,C)`çš„`numpy.ndarray`ï¼Œè½¬æ¢æˆå½¢çŠ¶ä¸º`[C,H,W]`ï¼Œå–å€¼èŒƒå›´æ˜¯`[0,1.0]`çš„`torch.FloatTensor`
  
- **class torchvision.transforms.Normalize(mean, std)**:
  - ç»™å®šå‡å€¼ï¼š`(R,G,B)` æ–¹å·®ï¼š`ï¼ˆRï¼ŒGï¼ŒBï¼‰`ï¼Œå°†ä¼šæŠŠ`Tensor`æ­£åˆ™åŒ–ã€‚å³ï¼š`Normalized_image=(image-mean)/std`
  
- cv2.imread(img, 1)ï¼šè¿”å›ç»“æœä¸º`type: numpy.ndarray `ï¼Œå¤šç»´æ•°ç»„

## ğŸ’¡ 4. Pytorchæ¨¡å‹æ„é€ 

###  4.1 ç»§æ‰¿Moduleç±»æ¥æ„é€ æ¨¡å‹

- è¿™é‡Œå®šä¹‰çš„MLPç±»é‡è½½äº†Moduleç±»çš„__init__å‡½æ•°å’Œforwardå‡½æ•°ã€‚å®ƒä»¬åˆ†åˆ«ç”¨äºåˆ›å»ºæ¨¡å‹å‚æ•°å’Œå®šä¹‰å‰å‘è®¡ç®—ã€‚å‰å‘è®¡ç®—ä¹Ÿå³æ­£å‘ä¼ æ’­ã€‚
```python
import torch
from torch import nn

class MLP(nn.Module):
    # å£°æ˜å¸¦æœ‰æ¨¡å‹å‚æ•°çš„å±‚ï¼Œè¿™é‡Œå£°æ˜äº†ä¸¤ä¸ªå…¨è¿æ¥å±‚
    def __init__(self, **kwargs):
        # è°ƒç”¨MLPçˆ¶ç±»Moduleçš„æ„é€ å‡½æ•°æ¥è¿›è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚è¿™æ ·åœ¨æ„é€ å®ä¾‹æ—¶è¿˜å¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°
        # å‚æ•°ï¼Œå¦‚â€œæ¨¡å‹å‚æ•°çš„è®¿é—®ã€åˆå§‹åŒ–å’Œå…±äº«â€ä¸€èŠ‚å°†ä»‹ç»çš„æ¨¡å‹å‚æ•°params
        super(MLP, self).__init__(**kwargs)
        self.hidden = nn.Linear(784, 256) # éšè—å±‚
        self.act = nn.ReLU()
        self.output = nn.Linear(256, 10)  # è¾“å‡ºå±‚


    # å®šä¹‰æ¨¡å‹çš„å‰å‘è®¡ç®—ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥xè®¡ç®—è¿”å›æ‰€éœ€è¦çš„æ¨¡å‹è¾“å‡º
    def forward(self, x):
        a = self.act(self.hidden(x))
        return self.output(a)
```

###  4.2 ä½¿ç”¨Sequentialç±»å®šä¹‰æ¨¡å‹

- å®ƒå¯ä»¥æ¥æ”¶ä¸€ä¸ªå­æ¨¡å—çš„æœ‰åºå­—å…¸ï¼ˆOrderedDictï¼‰æˆ–è€…ä¸€ç³»åˆ—å­æ¨¡å—ä½œä¸ºå‚æ•°æ¥é€ä¸€æ·»åŠ Moduleçš„å®ä¾‹
- æ¨¡å‹çš„å‰å‘è®¡ç®—å°±æ˜¯å°†è¿™äº›å®ä¾‹æŒ‰æ·»åŠ çš„é¡ºåºé€ä¸€è®¡ç®—
```python
import torch
from torch import nn
class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size
            nn.Sigmoid(),
            nn.MaxPool2d(2, 2), # kernel_size, stride
            nn.Conv2d(6, 16, 5),# in_channels, out_channels, kernel_size
            nn.Sigmoid(),
            nn.MaxPool2d(2, 2)
        )
        self.fc = nn.Sequential(
            nn.Linear(16*4*4, 120),
            nn.Sigmoid(),
            nn.Linear(120, 84),
            nn.Sigmoid(),
            nn.Linear(84, 10)
        )
    
    def forward(self, img):
        feature = self.conv(img)
        # viewç›¸å½“äºreshapeï¼Œè¿™é‡Œçš„img.shape[0]æ˜¯batch_sizeï¼Œ-1ä»£è¡¨è‡ªåŠ¨è®¡ç®—å‡ºæ¥çš„H*W*Channels
        output = self.fc(feature.view(img.shape[0], -1))
        return output
```

### 4.3 ModuleListç±»

- ModuleListæ¥æ”¶ä¸€ä¸ªå­æ¨¡å—çš„åˆ—è¡¨ä½œä¸ºè¾“å…¥ï¼Œç„¶åä¹Ÿå¯ä»¥ç±»ä¼¼Listé‚£æ ·è¿›è¡Œappendå’Œextendæ“ä½œ:
```python
net = nn.ModuleList([nn.Linear(784, 256), nn.ReLU()])
net.append(nn.Linear(256, 10)) # # ç±»ä¼¼Listçš„appendæ“ä½œ
print(net[-1])  # ç±»ä¼¼Listçš„ç´¢å¼•è®¿é—®
print(net)
# net(torch.zeros(1, 784)) # ä¼šæŠ¥NotImplementedError
# è¾“å‡º
Linear(in_features=256, out_features=10, bias=True)
ModuleList(
  (0): Linear(in_features=784, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=10, bias=True)
)
```
- æ—¢ç„¶Sequentialå’ŒModuleListéƒ½å¯ä»¥è¿›è¡Œåˆ—è¡¨åŒ–æ„é€ ç½‘ç»œï¼Œé‚£äºŒè€…åŒºåˆ«æ˜¯ä»€ä¹ˆå‘¢ã€‚
- ModuleListä»…ä»…æ˜¯ä¸€ä¸ªå‚¨å­˜å„ç§æ¨¡å—çš„åˆ—è¡¨ï¼Œè¿™äº›æ¨¡å—ä¹‹é—´æ²¡æœ‰è”ç³»ä¹Ÿæ²¡æœ‰é¡ºåºï¼ˆæ‰€ä»¥ä¸ç”¨ä¿è¯ç›¸é‚»å±‚çš„è¾“å…¥è¾“å‡ºç»´åº¦åŒ¹é…ï¼‰ï¼Œè€Œä¸”æ²¡æœ‰å®ç°forwardåŠŸèƒ½éœ€è¦è‡ªå·±å®ç°ï¼Œæ‰€ä»¥ä¸Šé¢æ‰§è¡Œnet(torch.zeros(1, 784))ä¼šæŠ¥NotImplementedErrorï¼›
- è€ŒSequentialå†…çš„æ¨¡å—éœ€è¦æŒ‰ç…§é¡ºåºæ’åˆ—ï¼Œè¦ä¿è¯ç›¸é‚»å±‚çš„è¾“å…¥è¾“å‡ºå¤§å°ç›¸åŒ¹é…ï¼Œå†…éƒ¨forwardåŠŸèƒ½å·²ç»å®ç°ã€‚

### 4.4 ModuleDictç±»
- ModuleDictæ¥æ”¶ä¸€ä¸ªå­æ¨¡å—çš„å­—å…¸ä½œä¸ºè¾“å…¥, ç„¶åä¹Ÿå¯ä»¥ç±»ä¼¼å­—å…¸é‚£æ ·è¿›è¡Œæ·»åŠ è®¿é—®æ“ä½œ:
```python
net = nn.ModuleDict({
    'linear': nn.Linear(784, 256),
    'act': nn.ReLU(),
})
net['output'] = nn.Linear(256, 10) # æ·»åŠ 
print(net['linear']) # è®¿é—®
print(net.output)
print(net)
# net(torch.zeros(1, 784)) # ä¼šæŠ¥NotImplementedError
# è¾“å‡º
Linear(in_features=784, out_features=256, bias=True)
Linear(in_features=256, out_features=10, bias=True)
ModuleDict(
  (act): ReLU()
  (linear): Linear(in_features=784, out_features=256, bias=True)
  (output): Linear(in_features=256, out_features=10, bias=True)
)
```
- å’ŒModuleListä¸€æ ·ï¼ŒModuleDictå®ä¾‹ä»…ä»…æ˜¯å­˜æ”¾äº†ä¸€äº›æ¨¡å—çš„å­—å…¸ï¼Œå¹¶æ²¡æœ‰å®šä¹‰forwardå‡½æ•°éœ€è¦è‡ªå·±å®šä¹‰ã€‚
- åŒæ ·ï¼ŒModuleDictä¹Ÿä¸Pythonçš„Dictæœ‰æ‰€ä¸åŒï¼ŒModuleDicté‡Œçš„æ‰€æœ‰æ¨¡å—çš„å‚æ•°ä¼šè¢«è‡ªåŠ¨æ·»åŠ åˆ°æ•´ä¸ªç½‘ç»œä¸­ã€‚

## ğŸ’¡ 5. Pytorchçš„CrossEntropyLoss

- é”™è¯¯æè¿°ï¼šè¯­ä¹‰åˆ†å‰²å®éªŒä¸­ï¼Œåœ¨å¯¹labelè¿›è¡Œonehotç¼–ç ä¹‹åï¼Œå°†å…¶å˜ä¸º(4,4,640,640)ï¼Œå®šä¹‰losså¦‚ä¸‹ï¼š
```python
criterion = nn.CrossEntropyLoss().to(device)
loss = criterion(output, label)
```
- æŠ¥é”™ï¼š**å¤§è‡´ä¸ºï¼ŒæœŸæœ›çš„targetæ˜¯3ç»´ï¼Œå´å¾—åˆ°äº†ä¸€ä¸ª4ç»´ã€‚**
- æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£å¦‚ä¸‹ï¼š
![](https://github.com/yearing1017/PyTorch_Note/blob/master/image/5-4.png)
- è¯¥æŸå¤±å‡½æ•°åŒ…å«äº†**softmaxå‡½æ•°**ï¼Œ**è¯¥æŸå¤±å‡½æ•°æœŸæœ›çš„targetæ˜¯åœ¨åƒç´ å€¼ä¸ºï¼ˆ0ï¼ŒC-1ï¼‰çš„ä¸€ä¸ªæ ‡æ³¨å›¾ã€‚ä¸æ ‡æ³¨å¥½çš„labelç›¸å¯¹åº”ï¼Œæ¯ä¸ªåƒç´ å€¼æ ‡æ³¨äº†ç±»åˆ«0-3ã€‚å…±4ç±»**
![](https://github.com/yearing1017/PyTorch_Note/blob/master/image/5-3.png)
- ä¸Šå›¾è¯¦ç»†è§£é‡Šäº†losså‡½æ•°çš„è¦æ±‚çš„shapeã€‚å¯¹äºè¯­ä¹‰åˆ†å‰²çš„4ç»´å‘é‡æ¥è¯´ï¼š**è¦æ±‚inputå³ç½‘ç»œçš„é¢„æµ‹ä¸º(N,C,H,W)ï¼Œtargetä¸º(N, H, W)ï¼Œä¸”target[i]åœ¨0-C-1ä¹‹é—´ã€‚**
- **æ”¹åŠ¨ï¼šå»æ‰onehotï¼Œç›´æ¥è¯»å…¥æ ‡æ³¨çš„labelï¼Œå› ä¸ºç¬¦åˆä¸Šè¿°è¦æ±‚ã€‚**
